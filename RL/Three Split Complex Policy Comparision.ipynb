{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from statistics import mean\n",
    "import numpy as np\n",
    "import sys\n",
    "import glob\n",
    "import math\n",
    "from scipy.special import comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name_train_250 = \"../Human Experiments/Data/RL_trajectories_1000_250.pickle\"\n",
    "file_obj_train_250 = open(file_name_train_250, 'rb')\n",
    "trajectories_train_250 = pickle.load(file_obj_train_250)\n",
    "trajectories_train_250 = [list(ele) for ele in trajectories_train_250]\n",
    "\n",
    "file_name_test_250 = \"../Human Experiments/Data/Human_trajectories_test_250.pickle\"\n",
    "file_obj_test_250 = open(file_name_test_250, 'rb')\n",
    "trajectories_test_250 = pickle.load(file_obj_test_250)\n",
    "trajectories_test_250 = [list(ele) for ele in trajectories_test_250]\n",
    "\n",
    "file_name_train_500 = \"../Human Experiments/Data/RL_trajectories_1000_500.pickle\"\n",
    "file_obj_train_500 = open(file_name_train_500, 'rb')\n",
    "trajectories_train_500 = pickle.load(file_obj_train_500)\n",
    "trajectories_train_500 = [list(ele) for ele in trajectories_train_500]\n",
    "\n",
    "file_name_test_500 = \"../Human Experiments/Data/Human_trajectories_test_500.pickle\"\n",
    "file_obj_test_500 = open(file_name_test_500, 'rb')\n",
    "trajectories_test_500 = pickle.load(file_obj_test_500)\n",
    "trajectories_test_500 = [list(ele) for ele in trajectories_test_500]\n",
    "\n",
    "test_size = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_policies(price_low_bound, price_upper_bound):\n",
    "    policies = []\n",
    "    for i in range(price_low_bound, price_upper_bound, 10):\n",
    "        for j in range(price_low_bound, price_upper_bound, 10):\n",
    "            for k in range(price_low_bound, price_upper_bound, 10):\n",
    "                for l in range(5):\n",
    "                    for m in range(5):\n",
    "                        for n in range(5):\n",
    "                            policy = (i, j, k, l, m, n)\n",
    "                            policies.append(policy)\n",
    "    return policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "policies = generate_policies(150, 260)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "166375"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(policies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_policy(policy, data, best_buys_cost, best_buys_idx, get_final_output):\n",
    "    if(len(policy)!=6):\n",
    "        raise ValueError(\"Number of parameters in this policy is \"+ str(len(policy))+\" when it should be 6\")\n",
    "    bought = []\n",
    "    bought_cost_only = []\n",
    "    bought_idx_only = []\n",
    "    t1 = policy[0]\n",
    "    t2 = policy[1]\n",
    "    t3 = policy[2]\n",
    "    d1 = policy[3]\n",
    "    d2 = policy[4]\n",
    "    d3 = policy[5]\n",
    "    for trajectory in data:\n",
    "        for idx, cost in enumerate(trajectory):\n",
    "            local_cat = int(idx/5)\n",
    "            local_idx = int(idx%5)\n",
    "            if(idx == len(trajectory) - 1):\n",
    "                bought.append((cost, idx))\n",
    "                bought_cost_only.append(cost)\n",
    "                bought_idx_only.append(idx)\n",
    "                break\n",
    "            elif(local_cat == 0):\n",
    "                if(cost > t1 and local_idx <= d1):\n",
    "                    continue\n",
    "                else: \n",
    "                    bought.append((cost, idx))\n",
    "                    bought_cost_only.append(cost)\n",
    "                    bought_idx_only.append(idx)\n",
    "                    break\n",
    "            elif(local_cat == 1):\n",
    "                if(cost > t2 and local_idx <= d2):\n",
    "                    continue\n",
    "                else: \n",
    "                    bought.append((cost, idx))\n",
    "                    bought_cost_only.append(cost)\n",
    "                    bought_idx_only.append(idx)\n",
    "                    break\n",
    "            elif(local_cat == 2):\n",
    "                if(cost > t3 and local_idx <= d3):\n",
    "                    continue\n",
    "                else: \n",
    "                    bought.append((cost, idx))\n",
    "                    bought_cost_only.append(cost)\n",
    "                    bought_idx_only.append(idx)\n",
    "                    break\n",
    "    error = [a_i - b_i for a_i, b_i in zip(bought_cost_only, best_buys_cost)]\n",
    "    correct_stops = (np.equal(bought_idx_only, best_buys_idx)).astype(int)\n",
    "    correct_stops = sum(correct_stops)\n",
    "    avg_error = sum(error)/len(data)\n",
    "    if(get_final_output):\n",
    "        return bought, avg_error, correct_stops\n",
    "    return avg_error, correct_stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Cost\n",
    "best_buy_250_train = [min(ele) for ele in trajectories_train_250]\n",
    "best_buy_250_test = [min(ele) for ele in trajectories_test_250]\n",
    "best_buy_500_train = [min(ele) for ele in trajectories_train_500]\n",
    "best_buy_500_test = [min(ele) for ele in trajectories_test_500]\n",
    "\n",
    "##Indices\n",
    "best_buy_250_train_idx = [ele.index(min(ele)) for ele in trajectories_train_250]\n",
    "best_buy_250_test_idx = [ele.index(min(ele)) for ele in trajectories_test_250]\n",
    "best_buy_500_train_idx = [ele.index(min(ele)) for ele in trajectories_train_500]\n",
    "best_buy_500_test_idx = [ele.index(min(ele)) for ele in trajectories_test_500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13.737, 524)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_policy((190, 210, 230, 4, 4, 3), trajectories_train_250, best_buy_250_train, best_buy_250_train_idx, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readfile(filename):\n",
    "    results = []\n",
    "    fileObject = open(filename,'rb')  \n",
    "    results = pickle.load(fileObject)\n",
    "    fileObject.close()\n",
    "    return results\n",
    "\n",
    "\n",
    "def get_all_filenames(directoryname):\n",
    "    txtfiles = []\n",
    "    for file in glob.glob(directoryname):\n",
    "        txtfiles.append(file)\n",
    "    return txtfiles\n",
    "\n",
    "\n",
    "def min_loc():\n",
    "    final_minimum = readfile('../Human Experiments/Tests/Human_minimum.pickle')\n",
    "    result = []\n",
    "    for i, res in enumerate(final_minimum):\n",
    "        temp_result = []\n",
    "        for j, traj_res in enumerate(res):\n",
    "            temp_result.append(traj_res[1])\n",
    "        result.append(temp_result)\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_final_results(directory):\n",
    "    filenames = get_all_filenames(directory)\n",
    "    final_results = [np.zeros(60),np.zeros(60)]\n",
    "    final_error = [np.zeros(60),np.zeros(60)]\n",
    "    final_minimum = readfile('../Human Experiments/Tests/Human_minimum.pickle')\n",
    "    for filename in filenames:\n",
    "        results = readfile(filename)\n",
    "        for i, res in enumerate(results):\n",
    "            temp_results = np.zeros(60)\n",
    "            temp_errors = np.zeros(60)\n",
    "            for j, traj_res in enumerate(res):\n",
    "                if final_minimum[i][j] == traj_res: temp_results[j] += 1\n",
    "                temp_errors[j] += traj_res[0]-final_minimum[i][j][0]\n",
    "            final_results[i] = np.add(final_results[i], temp_results)\n",
    "            final_error[i] = np.add(final_error[i], temp_errors)\n",
    "            \n",
    "    return final_results, final_error, len(filenames)\n",
    "\n",
    "def combine_final_results(results, t250):\n",
    "    final_results = np.zeros(60)\n",
    "    final_error = np.zeros(60)\n",
    "    final_minimum = readfile('../Human Experiments/Tests/Human_minimum.pickle')\n",
    "    for j, traj_res in enumerate(results):\n",
    "        if t250:\n",
    "            if final_minimum[0][j] == traj_res: final_results[j] += 1\n",
    "            final_error[j] += traj_res[0]-final_minimum[0][j][0]\n",
    "        else:\n",
    "            if final_minimum[1][j] == traj_res: final_results[j] += 1\n",
    "            final_error[j] += traj_res[0]-final_minimum[1][j][0]\n",
    "            \n",
    "    return final_results, final_error, 1\n",
    "\n",
    "def result_combine_LL(res, mloc, t250):\n",
    "    combine = np.zeros(15)\n",
    "    for j, idx in enumerate(res):\n",
    "        if t250: \n",
    "            if idx: combine[mloc[0][j]] += idx\n",
    "        else: \n",
    "            if idx: combine[mloc[1][j]] += idx\n",
    "    return combine\n",
    "\n",
    "def create_consolidated_LL(test_compile, test_num, human_compile, human_num, min_compile, t250=True):\n",
    "    if t250: test_compile = np.divide(test_compile,min_compile[0]*test_num)\n",
    "    else: test_compile = np.divide(test_compile,min_compile[1]*test_num)\n",
    "    consolidated = []\n",
    "    temp = []\n",
    "    for j, val in enumerate(human_compile):\n",
    "        if t250: temp.append((human_compile[j], min_compile[0][j]*human_num, test_compile[j]))\n",
    "        else: temp.append((human_compile[j], min_compile[1][j]*human_num, test_compile[j]))\n",
    "    consolidated.append(temp)\n",
    "    return consolidated\n",
    "\n",
    "def computeLogLikelihood(S, N, p):\n",
    "    p = p if p > 0.0 else 0.0+1e-10\n",
    "    p = p if p < 1.0 else 1.0-1e-10\n",
    "    if N == 0 :result = 0\n",
    "    else: result = math.log(comb(N, S)) + (S*math.log(p) + (N-S)*math.log(1.0-p))\n",
    "\n",
    "    return result\n",
    "\n",
    "def log_likelihood(results, t250=True):\n",
    "    mloc = min_loc()\n",
    "    min_compile = [np.zeros(15),np.zeros(15)]\n",
    "    for i, item in enumerate(mloc):\n",
    "        for idx in item:\n",
    "            min_compile[i][idx] += 1\n",
    "    test_res, test_err, test_num= combine_final_results(results, t250)\n",
    "    human_res, human_err, human_num = get_final_results('../Human Experiments/Tests/test*')\n",
    "    test_compile = result_combine_LL(test_res, mloc, t250)\n",
    "    human_compile = result_combine_LL(human_res[0], mloc, t250)\n",
    "    \n",
    "    consolidated = create_consolidated_LL(test_compile, test_num, human_compile, human_num, min_compile)\n",
    "    \n",
    "    result_LL = []\n",
    "    for i, traj in enumerate(consolidated):\n",
    "        temp = []\n",
    "        for j, val in enumerate(traj):\n",
    "            temp.append(computeLogLikelihood(val[0], val[1], val[2]))\n",
    "        result_LL.append(np.sum(temp)*-1)\n",
    "\n",
    "    return result_LL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_search(price_low_bound, price_upper_bound, data, best_buys_cost, best_buys_idx, t250 =True):\n",
    "    all_errors = []\n",
    "    all_correct_stops = []\n",
    "    LL_human = []\n",
    "    all_policies = generate_policies(price_low_bound, price_upper_bound)\n",
    "    for idx, policy in enumerate(all_policies):\n",
    "        bought, policy_avg_error, correct_stops = evaluate_policy(policy, data, best_buys_cost, best_buys_idx, True)\n",
    "        sys.stdout.flush()\n",
    "        sys.stdout.write(\"\\rPolicies Evaluated: {}/{}\".format(idx+1, len(all_policies)))\n",
    "        all_errors.append(policy_avg_error)\n",
    "        all_correct_stops.append(correct_stops)\n",
    "        LL_human.append(log_likelihood(bought, t250))\n",
    "    optimal_policy_by_ll_human = (min(LL_human), all_policies[LL_human.index(min(LL_human))])\n",
    "    optimal_policy_by_avg_error = (min(all_errors), all_policies[all_errors.index(min(all_errors))])\n",
    "    optimal_policy_by_opt_stop = (max(all_correct_stops), all_policies[all_correct_stops.index(max(all_correct_stops))])\n",
    "    print(min(LL_human), all_policies[LL_human.index(min(LL_human))])\n",
    "    return optimal_policy_by_avg_error, optimal_policy_by_opt_stop, optimal_policy_by_ll_human\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Route 1 (250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policies Evaluated: 27000/27000[120.11844661962371] (200, 230, 230, 4, 4, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((13.016666666666667, (200, 230, 230, 4, 4, 3)),\n",
       " (29, (200, 220, 230, 4, 4, 3)),\n",
       " ([120.11844661962371], (200, 230, 230, 4, 4, 3)))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_policy_250 = policy_search(180, 231, trajectories_test_250, best_buy_250_test, best_buy_250_test_idx)\n",
    "optimal_policy_250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14.716666666666667, 25)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result_avg_250, avg_error, correct_stops = evaluate_policy((200, 210, 230, 4, 4, 3), \n",
    "                                                                 trajectories_test_250, \n",
    "                                                                 best_buy_250_test, \n",
    "                                                                 best_buy_250_test_idx, \n",
    "                                                                 True)\n",
    "avg_error, correct_stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13.016666666666667, 29)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result_best_250, avg_error, correct_stops = evaluate_policy((200, 230, 230, 4, 4, 3), \n",
    "                                                                 trajectories_test_250, \n",
    "                                                                 best_buy_250_test, \n",
    "                                                                 best_buy_250_test_idx, \n",
    "                                                                 True)\n",
    "avg_error, correct_stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17.483333333333334, 24)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result_opt_stop_250, avg_error, correct_stops = evaluate_policy((200, 210, 220, 4, 4, 3), \n",
    "                                                                 trajectories_test_250, \n",
    "                                                                 best_buy_250_test, \n",
    "                                                                 best_buy_250_test_idx, \n",
    "                                                                 True)\n",
    "avg_error, correct_stops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Route 2 (500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policies Evaluated: 91125/91125[173.52564464800335] (430, 420, 440, 4, 4, 3)\n"
     ]
    }
   ],
   "source": [
    "optimal_policy_500 = policy_search(400, 481, trajectories_test_500, best_buy_500_test, best_buy_500_test_idx, t250=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12.8, (410, 450, 480, 4, 4, 3)),\n",
       " (36, (410, 450, 450, 4, 4, 3)),\n",
       " ([173.52564464800335], (430, 420, 440, 4, 4, 3)))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_policy_500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19.333333333333332, 34)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result_avg_500, avg_error, correct_stops = evaluate_policy((410, 420, 460, 4, 4, 4), \n",
    "                                                                 trajectories_test_500, \n",
    "                                                                 best_buy_500_test, \n",
    "                                                                 best_buy_500_test_idx, \n",
    "                                                                 True)\n",
    "avg_error, correct_stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28.166666666666668, 27)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result_best_500, avg_error, correct_stops = evaluate_policy((430, 420, 440, 4, 4, 3), \n",
    "                                                                 trajectories_test_500, \n",
    "                                                                 best_buy_500_test, \n",
    "                                                                 best_buy_500_test_idx, \n",
    "                                                                 True)\n",
    "avg_error, correct_stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30.9, 31)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result_opt_stop_500, avg_error, correct_stops = evaluate_policy((400, 420, 430, 4, 4, 3), \n",
    "                                                                 trajectories_test_500, \n",
    "                                                                 best_buy_500_test, \n",
    "                                                                 best_buy_500_test_idx, \n",
    "                                                                 True)\n",
    "avg_error, correct_stops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "rl_three_split_avg = [final_result_avg_250, final_result_avg_500]\n",
    "rl_three_split_opt_stop = [final_result_opt_stop_250, final_result_opt_stop_500]\n",
    "rl_three_split_best = [final_result_best_250, final_result_best_500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(obj, filename):\n",
    "    final_file_object = open(filename, 'wb')\n",
    "    pickle.dump(obj, final_file_object)\n",
    "    final_file_object.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(rl_three_split_avg, \"../Human Experiments/Tests/rl_three_split_avg\")\n",
    "save_data(rl_three_split_opt_stop, \"../Human Experiments/Tests/rl_three_split_opt_stop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(rl_three_split_best, \"../Human Experiments/Tests/rl_three_split_best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
