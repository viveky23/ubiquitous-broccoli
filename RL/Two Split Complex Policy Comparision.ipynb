{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from statistics import mean\n",
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name_train_250 = \"../Human Experiments/Data/RL_trajectories_1000_250.pickle\"\n",
    "file_obj_train_250 = open(file_name_train_250, 'rb')\n",
    "trajectories_train_250 = pickle.load(file_obj_train_250)\n",
    "trajectories_train_250 = [list(ele) for ele in trajectories_train_250]\n",
    "\n",
    "file_name_test_250 = \"../Human Experiments/Data/Human_trajectories_test_250.pickle\"\n",
    "file_obj_test_250 = open(file_name_test_250, 'rb')\n",
    "trajectories_test_250 = pickle.load(file_obj_test_250)\n",
    "trajectories_test_250 = [list(ele) for ele in trajectories_test_250]\n",
    "\n",
    "file_name_train_500 = \"../Human Experiments/Data/RL_trajectories_1000_500.pickle\"\n",
    "file_obj_train_500 = open(file_name_train_500, 'rb')\n",
    "trajectories_train_500 = pickle.load(file_obj_train_500)\n",
    "trajectories_train_500 = [list(ele) for ele in trajectories_train_500]\n",
    "\n",
    "file_name_test_500 = \"../Human Experiments/Data/Human_trajectories_test_500.pickle\"\n",
    "file_obj_test_500 = open(file_name_test_500, 'rb')\n",
    "trajectories_test_500 = pickle.load(file_obj_test_500)\n",
    "trajectories_test_500 = [list(ele) for ele in trajectories_test_500]\n",
    "\n",
    "test_size = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_policies_two_split(price_low_bound, price_upper_bound, step_size, split):\n",
    "    policies = []\n",
    "    for i in range(price_low_bound, price_upper_bound, step_size):\n",
    "        for j in range(price_low_bound, price_upper_bound, step_size):\n",
    "            for k in range(split[0]):\n",
    "                for l in range(split[1]):\n",
    "                    policy = (i, j, k, l)\n",
    "                    policies.append(policy)\n",
    "    return policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6776"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policies = generate_policies_two_split(150, 260, 10, (8,7))\n",
    "len(policies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_policy_two_split(policy, data, best_buys_cost, best_buys_idx, split, get_final_output):\n",
    "    if(len(policy)!=4):\n",
    "        raise ValueError(\"Number of parameters in this policy is \"+ str(len(policy))+\" when it should be 4\")\n",
    "    bought = []\n",
    "    bought_cost_only = []\n",
    "    bought_idx_only = []\n",
    "    t1 = policy[0]\n",
    "    t2 = policy[1]\n",
    "    d1 = policy[2]\n",
    "    d2 = policy[3]\n",
    "    for trajectory in data:\n",
    "        for idx, cost in enumerate(trajectory):\n",
    "            if (idx<split[0]):\n",
    "                local_idx = idx\n",
    "            else:\n",
    "                local_idx = idx-split[0]\n",
    "            if(idx == len(trajectory) - 1):\n",
    "                bought.append((cost, idx))\n",
    "                bought_cost_only.append(cost)\n",
    "                bought_idx_only.append(idx)\n",
    "                break\n",
    "            elif(idx < split[0]):\n",
    "                if(cost > t1 and local_idx < d1):\n",
    "                    continue\n",
    "                else: \n",
    "                    bought.append((cost, idx))\n",
    "                    bought_cost_only.append(cost)\n",
    "                    bought_idx_only.append(idx)\n",
    "                    break\n",
    "            elif(idx >= split[0]):\n",
    "                if(cost > t2 and local_idx < d2):\n",
    "                    continue\n",
    "                else: \n",
    "                    bought.append((cost, idx))\n",
    "                    bought_cost_only.append(cost)\n",
    "                    bought_idx_only.append(idx)\n",
    "                    break\n",
    "    error = [a_i - b_i for a_i, b_i in zip(bought_cost_only, best_buys_cost)]\n",
    "    correct_stops = (np.equal(bought_idx_only, best_buys_idx)).astype(int)\n",
    "    correct_stops = sum(correct_stops)\n",
    "    avg_error = sum(error)/len(data)\n",
    "    if(get_final_output):\n",
    "        return bought, avg_error, correct_stops\n",
    "    return avg_error, correct_stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Cost\n",
    "best_buy_250_train = [min(ele) for ele in trajectories_train_250]\n",
    "best_buy_250_test = [min(ele) for ele in trajectories_test_250]\n",
    "best_buy_500_train = [min(ele) for ele in trajectories_train_500]\n",
    "best_buy_500_test = [min(ele) for ele in trajectories_test_500]\n",
    "\n",
    "##Indices\n",
    "best_buy_250_train_idx = [ele.index(min(ele)) for ele in trajectories_train_250]\n",
    "best_buy_250_test_idx = [ele.index(min(ele)) for ele in trajectories_test_250]\n",
    "best_buy_500_train_idx = [ele.index(min(ele)) for ele in trajectories_train_500]\n",
    "best_buy_500_test_idx = [ele.index(min(ele)) for ele in trajectories_test_500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44.642, 178)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_policy_two_split((180, 220, 7, 0), trajectories_train_250, best_buy_250_train, best_buy_250_train_idx, (8,7), False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_search_two_split(price_low_bound, price_upper_bound, data, best_buys_cost, best_buys_idx, step_size, split):\n",
    "    all_errors = []\n",
    "    all_correct_stops = []\n",
    "    all_policies = generate_policies_two_split(price_low_bound, price_upper_bound, step_size, split)\n",
    "    for idx, policy in enumerate(all_policies):\n",
    "        policy_avg_error, correct_stops = evaluate_policy_two_split(policy, data, best_buys_cost, best_buys_idx, split, False)\n",
    "        sys.stdout.flush()\n",
    "        sys.stdout.write(\"\\rProgress: {}/{}\".format(idx+1, len(all_policies)))\n",
    "        all_errors.append(policy_avg_error)\n",
    "        all_correct_stops.append(correct_stops)\n",
    "    optimal_policy_by_avg_error = (min(all_errors), all_policies[all_errors.index(min(all_errors))])\n",
    "    optimal_policy_by_opt_stop = (max(all_correct_stops), all_policies[all_correct_stops.index(max(all_correct_stops))])\n",
    "    return optimal_policy_by_avg_error, optimal_policy_by_opt_stop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Route 1 (250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split 8-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 2016/2016"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((24.737, (220, 180, 7, 0)), (341, (210, 180, 7, 0)))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_policy_250 = policy_search_two_split(180, 231, trajectories_train_250, \n",
    "                                             best_buy_250_train, \n",
    "                                             best_buy_250_train_idx, \n",
    "                                             10, (8,7))\n",
    "optimal_policy_250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26.133333333333333, 10)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result_8_7_250, avg_error, correct_stops = evaluate_policy_two_split((220, 180, 7, 0), trajectories_test_250, \n",
    "                          best_buy_250_test, \n",
    "                          best_buy_250_test_idx, \n",
    "                          (8,7), True)\n",
    "avg_error, correct_stops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split 10-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 1800/1800"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((20.57, (220, 180, 9, 0)), (401, (210, 180, 9, 0)))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_policy_250_alt_split_1 = policy_search_two_split(180, 231, trajectories_train_250, \n",
    "                                             best_buy_250_train, \n",
    "                                             best_buy_250_train_idx, \n",
    "                                             10, (10,5))\n",
    "optimal_policy_250_alt_split_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23.066666666666666, 12)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result_10_5_250, avg_error, correct_stops = evaluate_policy_two_split((220, 180, 9, 0), trajectories_test_250, \n",
    "                          best_buy_250_test, \n",
    "                          best_buy_250_test_idx, \n",
    "                          (10,5), True)\n",
    "avg_error, correct_stops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split 5-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 1800/1800"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((30.328, (230, 180, 4, 0)), (241, (210, 180, 4, 0)))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_policy_250_alt_split_2 = policy_search_two_split(180, 231, trajectories_train_250, \n",
    "                                             best_buy_250_train, \n",
    "                                             best_buy_250_train_idx, \n",
    "                                             10, (5,10))\n",
    "optimal_policy_250_alt_split_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24.683333333333334, 8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result_5_10_250, avg_error, correct_stops = evaluate_policy_two_split((230, 180, 4, 0), trajectories_test_250, \n",
    "                          best_buy_250_test, \n",
    "                          best_buy_250_test_idx, \n",
    "                          (5,10), True)\n",
    "avg_error, correct_stops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Route 2 (500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split 8-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 10976/10976((46.291, (440, 370, 7, 0)), (374, (420, 370, 7, 0)))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(44.96666666666667, 15)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_policy_500_alt1 = policy_search_two_split(370, 501, trajectories_train_500, \n",
    "                                   best_buy_500_train, \n",
    "                                   best_buy_500_train_idx, \n",
    "                                   10, (8,7))\n",
    "print(optimal_policy_500_alt1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44.96666666666667, 15)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result_8_7_500, avg_error, correct_stops = evaluate_policy_two_split((440, 370, 7, 0), trajectories_test_500, \n",
    "                          best_buy_500_test, \n",
    "                          best_buy_500_test_idx, \n",
    "                          (8,7), True)\n",
    "avg_error, correct_stops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split 10-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 9800/9800"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((39.629, (430, 370, 9, 0)), (444, (420, 370, 9, 0)))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_policy_500 = policy_search_two_split(370, 501, trajectories_train_500, \n",
    "                                   best_buy_500_train, \n",
    "                                   best_buy_500_train_idx, \n",
    "                                   10, (10,5))\n",
    "optimal_policy_500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42.11666666666667, 18)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result_10_5_500, avg_error, correct_stops = evaluate_policy_two_split((430, 370, 9, 0), trajectories_test_500, \n",
    "                          best_buy_500_test, \n",
    "                          best_buy_500_test_idx, \n",
    "                          (10,5), True)\n",
    "avg_error, correct_stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 9800/9800"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((61.828, (460, 370, 4, 0)), (258, (430, 370, 4, 0)))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_policy_500 = policy_search_two_split(370, 501, trajectories_train_500, \n",
    "                                   best_buy_500_train, \n",
    "                                   best_buy_500_train_idx, \n",
    "                                   10, (5,10))\n",
    "optimal_policy_500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50.13333333333333, 10)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result_5_10_500, avg_error, correct_stops = evaluate_policy_two_split((460, 370, 4, 0), trajectories_test_500, \n",
    "                          best_buy_500_test, \n",
    "                          best_buy_500_test_idx, \n",
    "                          (5,10), True)\n",
    "avg_error, correct_stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "rl_two_split_8_7 = [final_result_8_7_250 + final_result_8_7_500]\n",
    "rl_two_split_5_10 = [final_result_5_10_250 + final_result_5_10_500]\n",
    "rl_two_split_10_5 = [final_result_10_5_250 + final_result_10_5_500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(obj, filename):\n",
    "    final_file_object = open(filename, 'wb')\n",
    "    pickle.dump(obj, final_file_object)\n",
    "    final_file_object.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(rl_two_split_8_7, \"../Human Experiments/Tests/rl_two_split_8_7\")\n",
    "save_data(rl_two_split_5_10, \"../Human Experiments/Tests/rl_two_split_5_10\")\n",
    "save_data(rl_two_split_10_5, \"../Human Experiments/Tests/rl_two_split_10_5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
